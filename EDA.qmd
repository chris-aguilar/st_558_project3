---
title: "EDA"
author: "Chris Aguilar"
format: html
editor: visual
---

## Introduction

We'll be looking at the relationship between diabetes occurrence and several health predictors given in this [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/). The data comes from the Behavioral Risk Factor Surveillance System, a telephone survey collected by the CDC. We'll be using the 2015 version of the data for exploration, analysis, and machine learning.

The data contains information such as the occurrence of diabetes, various diet-related predictors (fruit/veggie consumption, alcohol), behavioral variables (exercise, smoker, doctor visits), demographic information (sex, education, income), and a few subjective variables where respondents are asked about their health.

We'll keep all variables, but be focusing on health/disease history variables, diet variables, a few behavioral variables, sex, and health insurance.

The goal of this exploratory data analysis (EDA) is to identify any variables that may be indicative of a higher probability of a respondent being diabetic or pre-diabetic. We'll get an intuition of this through numerical summaries and visualizations, then test predictive ability of the input variables on `Diabetic_binary` through machine learning models.

## Ingesting data

We read data in and select the variables of interest previously mentioned. The description of the data indicates that while all variables are numerically coded, only BMI, GenHlth and PhysHlth are truly numeric. The rest are categorical variables. 

However, all the categorical variables except Age, Income, Education, and General Health are binary. So we'll recategorize these four for levels that make more sense.

```{r read prep data}
library(readr)
library(dplyr)
library(stringr)

diabetes2015 <- read_csv("data/diabetes_binary_health_indicators_BRFSS2015.csv")

# helper function to extract level code and level translation
getLevels <- function(x, value_name = "value") {
  # grabbing digits at beginning of string
  index <- str_extract(x, "^\\d{1,2}") |> as.integer()
  # Grabbing everything that starts with a letter onwards
  value <- str_extract(x, "[A-Za-z](.+)")
  # putting index and value into data frame for joining later
  res <- data.frame(index = index)
  res[[value_name]] <- value
  res
}

# factor levels to use for some vars, obtained from discussion section using readClipboard()
ages <- c("1 Age 18 to 24", "2 Age 25 to 29", "3 Age 30 to 34", "4 Age 35 to 39", 
"5 Age 40 to 44", "6 Age 45 to 49", "7 Age 50 to 54", "8 Age 55 to 59", 
"9 Age 60 to 64", "10 Age 65 to 69", "11 Age 70 to 74", "12 Age 75 to 79", 
"13 Age 80 or older")

edu <- c("1 Never attended school or only kindergarten", "2 Grades 1 through 8 (Elementary)", 
"3 Grades 9 through 11 (Some high school)", "4 Grade 12 or GED (High school graduate)", 
"5 College 1 year to 3 years (Some college or technical school)", 
"6 College 4 years or more (College graduate)")

income <- c("1 Less than $10,000", "2 Less than $15,000 ($10,000 to less than $15,000)", 
"3 Less than $20,000 ($15,000 to less than $20,000)", "4 Less than $25,000 ($20,000 to less than $25,000)", 
"5 Less than $35,000 ($25,000 to less than $35,000)", "6 Less than $50,000 ($35,000 to less than $50,000)", 
"7 Less than $75,000 ($50,000 to less than $75,000)", "8 More than $75,000"
)

gen_health <- c("1 excellent", "2 very good", "3 good", "4 fair", "5 poor")

# reference tables
age_table <- getLevels(ages, "age_levels")
edu_table <- getLevels(edu, "edu_levels")
income_table <- getLevels(income, "inc_levels")
gen_health_table <- getLevels(gen_health, "health_levels")

# Grabbing diabetes data, joining translated categorical variables, and dropping redundant default variables
diabetes2015 <- diabetes2015 |>
  left_join(age_table, by = join_by(Age == index)) |>
  left_join(edu_table, by = join_by(Education == index)) |>
  left_join(income_table, by = join_by(Income == index)) |>
  left_join(gen_health_table, by = join_by(GenHlth == index)) |>
  select(-Age, -Education, -Income, -GenHlth) |> # dropping baseline variables
  mutate(Diabetes_binary = ifelse(Diabetes_binary == 1, "yes", "no")) |>
  mutate(across(where(is.character), factor)) # making the relevant variables factors
```

## EDA

We've cleaned up some categorical variables to have more legible levels, and left the others as-is as we consider the indicator values self-explanatory: 0 if false, 1 if true. If the variable is not binary, then it is considered truly quantitative.

### Class imbalance check and NAs

We now do some quick explorations of the data. We first check for any NAs. Also, since `Diabetes_binary` is our response variable of interest, we'll start EDA with that variable.

```{r response eda}

# check NA
diabetes2015 |> anyNA()

# check distribution
diabetes2015 |> 
  count(Diabetes_binary) |>
  mutate(prop = n / sum(n))
  
```

`Diabetes_binary` is binary, as the name suggests, and the prevalence of diabetes in this data set is about 14%, so we exhibit some class imbalance we'll keep in mind for any modeling. There are no overtly missing values.

### Univariate summaries

Next, we'll look at univariate summaries.

```{r univar summaries}

summary(diabetes2015)

```

Nothing seems out of the ordinary based on the univariate summaries, **except** for `BMI`: there's a max value of 98, which seems really large.

In metric units, $$BMI = mass\ (kg) / height^2\  (m)$$ so mass can be calculated as $$BMI \times height^2 = mass$$ 

So if we assume a realistic height of 2 meters with a BMI of 98, one could be estimated to weigh `{r} 98 * 2^2` kilograms, or `{r 98 * 2^2 * 2.2}` pounds. It's pathologically heavy but not impossible. [Heavier weights have been recorded.](https://en.wikipedia.org/wiki/Jon_Brower_Minnoch)

```{r bmi plot}

library(ggplot2)

diabetes2015 |>
  ggplot(aes(x = BMI)) + 
  geom_histogram() +
  labs(title = "Histogram of BMIs")

```

We'll assume the values are recorded correctly and refrain from deleting records.

### Bivariate summaries, numeric predictors

We'll now check numeric distributions with respect to our binary variable of interest.

```{r densities and diabetes}
library(tidyr)

diabetes2015 |>
  select(Diabetes_binary, BMI, MentHlth, PhysHlth) |>
  pivot_longer(BMI:PhysHlth, names_to = "Predictor") |>
  ggplot(aes(x = value, y = Predictor, col = Diabetes_binary)) +
  geom_boxplot() +
  labs(title = "Distributions of numeric predictors by diabetes indication")
```

Just eyeballing the results, it looks like `BMI` may possibly reflect a meaningful difference in diabetes occurrence, as higher `BMI` values suggest higher diabetes rates.

### Bivariate summaries, binary predictors

Now we'll plot differences in binary predictors by diabetes occurrence.

```{r binary predictors}

diabetes2015 |>
  select(-BMI, -MentHlth, -PhysHlth, -age_levels, -inc_levels, -edu_levels, -health_levels) |>
  group_by(Diabetes_binary) |>
  summarize(across(everything(), mean)) |>
  pivot_longer(!Diabetes_binary, names_to = "Predictor") |>
  ggplot(aes(x = value, y = Predictor, fill = Diabetes_binary)) +
  geom_col(position = "dodge")
```

Looking at predictor rates for both levels of `Diabetes_binary`, we see that disease/health variables seem to show the largest within-variable difference. These will likely be useful predictors. But just about every predictor except the health insurance/health care cost ones seem to suggest slight differences.

### Bivariate summaries, multi-level categorical predictors

Lastly, we'll check out `Diabetes_binary` and counts for the four multi-level categorical predictors.

```{r categorical predictors}

diabetes2015 |>
  select(Diabetes_binary, age_levels, edu_levels, inc_levels, health_levels) |>
  pivot_longer(!Diabetes_binary, names_to = "Predictor") |>
  count(Diabetes_binary, Predictor, value) |>
  ggplot(aes(x = n, y = value, fill = Diabetes_binary)) + 
  geom_col(position = "dodge") +
  facet_wrap( ~ Predictor, scales = "free_y")
```

There appear to exist differences in `Diabetes_binary` for different age, income, health and education groups. Older age groups, lower health, education, and income groups all suggest higher diabetes rates.

## Modeling

Next, we'll train a few models to predict pre-diabetes or diabetes using some of the variables we just explored.

[Click here for the Modeling page!](docs/Modeling.html)
